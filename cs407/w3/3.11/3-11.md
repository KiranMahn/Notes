# 3.11 Bias in Biometrics 

# Gender Shades: Summary

**Gender Shades** is a seminal study by Joy Buolamwini and Dr. Timnit Gebru published in 2018. The study investigates bias in commercial facial recognition systems by examining how these systems perform across different demographic groups, particularly focusing on the intersection of race and gender.

## Key Findings

- The researchers evaluated facial recognition systems from major companies, including IBM, Microsoft, and Face++.
- They analyzed the accuracy of these systems on a dataset comprising images of darker-skinned and lighter-skinned individuals, and across male and female genders.
- The study found that facial recognition systems had higher error rates when identifying darker-skinned and female faces compared to lighter-skinned and male faces.
- The disparity was most pronounced for darker-skinned women, where error rates were as high as 34.7%, while for lighter-skinned men, the error rate was less than 1%.

## Significance

- "Gender Shades" highlighted the potential harms of deploying biased AI systems, including reinforcing existing societal biases and perpetuating discrimination.
- It emphasized the need for more inclusive training datasets and the development of equitable AI technologies.
- The study has been influential in raising awareness about algorithmic bias and has led to policy discussions and improvements in AI ethics and standards.

## Conclusion

"Gender Shades" underscores the importance of examining and addressing biases in AI systems to ensure fair and equitable technology for all users. The work has been a catalyst for further research and policy changes aimed at mitigating bias in AI.

